{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUbDm5GPFvkH"
      },
      "outputs": [],
      "source": [
        "pip install langchain langchain-community langchain-google-genai langchain-huggingface langchain-chroma sentence-transformers beautifulsoup4 rank_bm25 python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain.agents import create_agent\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "wRSgsXQ2Krf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Ingresa la API Key de Gemini: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7wUMot1gWZo",
        "outputId": "06aef332-8e5d-49cc-f3e1-c2694a97599a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingresa la API Key de Gemini: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 1. HYBRID RETRIEVER CON RRF (Reciprocal Rank Fusion)\n",
        "# =========================================================\n",
        "class HybridRetriever:\n",
        "    \"\"\"\n",
        "    Usamos RRF y asigna un puntaje basado en la posición del documento en ambos rankings.\n",
        "    \"\"\"\n",
        "    def __init__(self, vector_retriever, bm25_retriever, k=3, rrf_k=60):\n",
        "        self.vector = vector_retriever\n",
        "        self.bm25 = bm25_retriever\n",
        "        self.k = k\n",
        "        self.rrf_k = rrf_k\n",
        "\n",
        "    def invoke(self, query: str):\n",
        "        # Obtenemos más candidatos de los necesarios para poder re-rankear\n",
        "        docs_vec = self.vector.invoke(query)\n",
        "        docs_kw = self.bm25.invoke(query)\n",
        "\n",
        "        scores = {}\n",
        "\n",
        "        # Aplicamos fórmula RRF: 1 / (rrf_k + rank)\n",
        "        for rank, doc in enumerate(docs_vec):\n",
        "            scores[doc.page_content] = scores.get(doc.page_content, 0) + 1 / (self.rrf_k + rank + 1)\n",
        "\n",
        "        for rank, doc in enumerate(docs_kw):\n",
        "            scores[doc.page_content] = scores.get(doc.page_content, 0) + 1 / (self.rrf_k + rank + 1)\n",
        "\n",
        "        # Ordenamos por score y reconstruimos los objetos Document\n",
        "        sorted_content = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Recuperamos la metadata original si es necesaria (aquí simplificado)\n",
        "        unique_docs = []\n",
        "        all_docs = docs_vec + docs_kw\n",
        "        for content, score in sorted_content[:self.k]:\n",
        "            for d in all_docs:\n",
        "                if d.page_content == content:\n",
        "                    unique_docs.append(d)\n",
        "                    break\n",
        "        return unique_docs"
      ],
      "metadata": {
        "id": "Gy2ci4C9FwnD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2. MOTOR DE CONOCIMIENTO (Con Filtro de Wikipedia)\n",
        "# =========================================================\n",
        "class KnowledgeEngine:\n",
        "    def __init__(self, url: str):\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
        "        )\n",
        "\n",
        "        self.llm = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        self.load_and_process(url)\n",
        "\n",
        "    def load_and_process(self, url: str):\n",
        "        #Filtramos solo el contenido principal de Wikipedia (clase mw-parser-output)\n",
        "        loader = WebBaseLoader(\n",
        "            web_path=url,\n",
        "            bs_kwargs={\n",
        "                \"parse_only\": None\n",
        "            }\n",
        "        )\n",
        "        # Filtro de etiquetas para evitar \"basura\" común\n",
        "        loader.requests_kwargs = {'verify': False}\n",
        "        docs = loader.load()\n",
        "\n",
        "        # Limpieza simple de contenido para Wikipedia\n",
        "        for doc in docs:\n",
        "            if \"mw-parser-output\" in doc.page_content:\n",
        "                 doc.page_content = doc.page_content.split(\"Véase también\")[0]\n",
        "\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200\n",
        "        )\n",
        "\n",
        "        self.splits = splitter.split_documents(docs)\n",
        "\n",
        "        vectorstore = Chroma.from_documents(\n",
        "            documents=self.splits,\n",
        "            embedding=self.embeddings\n",
        "        )\n",
        "\n",
        "        # Aumentamos el fetch inicial a 10 para que RRF tenga de dónde elegir\n",
        "        self.vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "        self.bm25_retriever = BM25Retriever.from_documents(self.splits)\n",
        "        self.bm25_retriever.k = 10\n",
        "\n",
        "        self.hybrid = HybridRetriever(\n",
        "            self.vector_retriever,\n",
        "            self.bm25_retriever,\n",
        "            k=4\n",
        "        )"
      ],
      "metadata": {
        "id": "nmMpO3ljMLI4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3. HERRAMIENTA Y AGENTE\n",
        "# =========================================================\n",
        "engine = KnowledgeEngine(\"https://es.wikipedia.org/wiki/Toxina\")\n",
        "\n",
        "@tool\n",
        "def research_tool(query: str):\n",
        "    \"\"\"Busca información precisa en la base de conocimiento.\"\"\"\n",
        "    docs = engine.hybrid.invoke(query)\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "agent = create_agent(\n",
        "    model=engine.llm,\n",
        "    tools=[research_tool],\n",
        "    system_prompt=SystemMessage(\n",
        "      content=\"Eres un Analista de Datos Senior. Usa la herramienta para obtener hechos. \"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "O6PVphnXML6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 4. EJECUCIÓN\n",
        "# =========================================================\n",
        "result = agent.invoke({\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"Por quién fue introducido el término toxina?\")\n",
        "    ]\n",
        "})\n",
        "\n",
        "for message in result[\"messages\"]:\n",
        "    message.pretty_print()"
      ],
      "metadata": {
        "id": "TclLJZ_mMPyQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}